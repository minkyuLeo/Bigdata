{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "id": "x9dQ3OPwT2y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc3b876-32f8-4a1a-add4-789785dd849c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdY70FGW9I9H",
        "outputId": "1fc9d9c6-c302-402a-cd11-1fff7fbe63ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "metadata": {
        "id": "mypV8EkR9a-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import json\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: 사전 학습된 감성 분석 모델 로드\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "# 최대 입력 길이 설정\n",
        "MAX_TOKEN_LENGTH = 512\n",
        "\n",
        "# 레이블 매핑 (LABEL_0 -> NEGATIVE, LABEL_1 -> POSITIVE)\n",
        "label_mapping = {\"LABEL_0\": \"NEGATIVE\", \"LABEL_1\": \"POSITIVE\"}\n",
        "\n",
        "# Step 2: JSON 파일 로드\n",
        "file_path = \"/content/cleaned_english_comments_no_emojis.json\"  # 원본 파일 경로\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Step 3: 각 경기별로 감성 분석 결과 추가\n",
        "print(\"Sentiment analysis in progress...\")\n",
        "for match in tqdm(data, desc=\"Processing matches\"):\n",
        "    comments = match.get(\"comments\", [])  # 댓글 목록 가져오기\n",
        "    if comments:\n",
        "        # 댓글에 대해 감성 분석 수행\n",
        "        results = []\n",
        "        for comment in comments:\n",
        "            # 토큰 길이가 512를 초과하면 앞부분만 처리\n",
        "            if len(comment) > MAX_TOKEN_LENGTH:\n",
        "                truncated_comment = comment[:MAX_TOKEN_LENGTH]\n",
        "                result = sentiment_model(truncated_comment)[0]\n",
        "            else:\n",
        "                result = sentiment_model(comment)[0]\n",
        "\n",
        "            # 레이블 매핑 적용\n",
        "            result[\"label\"] = label_mapping.get(result[\"label\"], result[\"label\"])\n",
        "            results.append(result)\n",
        "\n",
        "        sentiments = [result[\"label\"] for result in results]  # 매핑된 감성 레이블 가져오기\n",
        "\n",
        "        # 감성별 개수 세기\n",
        "        sentiment_counts = Counter(sentiments)\n",
        "        total_comments = len(sentiments)\n",
        "\n",
        "        # 감성 비율 계산 (백분율)\n",
        "        sentiment_ratios = {\n",
        "            \"POSITIVE\": sentiment_counts.get(\"POSITIVE\", 0) / total_comments * 100,  # 긍정 비율\n",
        "            \"NEGATIVE\": sentiment_counts.get(\"NEGATIVE\", 0) / total_comments * 100   # 부정 비율\n",
        "        }\n",
        "\n",
        "        # 감성 분석 결과를 경기 데이터에 추가\n",
        "        match[\"comments_analysis\"] = {\n",
        "            \"sentiment_ratios\": sentiment_ratios,  # 감성 비율 추가\n",
        "            \"comments\": [  # 댓글별 분석 결과 추가\n",
        "                {\n",
        "                    \"comment\": comment,\n",
        "                    \"sentiment\": result[\"label\"],  # 매핑된 감성 레이블\n",
        "                    \"score\": result[\"score\"]      # 모델의 신뢰도 점수\n",
        "                }\n",
        "                for comment, result in zip(comments, results)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "# Step 4: 수정된 데이터를 새로운 JSON 파일로 저장\n",
        "output_path = \"/content/sentiment_analysis_with_original_structure.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"Sentiment analysis completed and saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZRfdhyt4sJI",
        "outputId": "9892b276-f209-41c4-f00a-1fc65936e133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis in progress...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing matches: 100%|██████████| 130/130 [02:52<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis completed and saved to /content/sentiment_analysis_with_original_structure.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: 수정된 데이터를 새로운 JSON 파일로 저장\n",
        "output_path = \"/content/drive/MyDrive/Colab Notebooks/빅데이터/sentiment_analysis_with_original_structure.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"Sentiment analysis completed and saved to {output_path}\")"
      ],
      "metadata": {
        "id": "D4V3v7e08I-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718374d7-d531-4b13-8825-e58a4e3ff4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis completed and saved to /content/drive/MyDrive/Colab Notebooks/빅데이터/sentiment_analysis_with_original_structure.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxpKFoNi_y9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}